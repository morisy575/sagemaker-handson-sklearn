{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Amazon SageMaker ハンズオン：Scikit-learn コンテナを用いて Iris データセットの 学習・推論を行なう\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "このチュートリアルでは、[Scikit-learn](https://scikit-learn.org/stable/) を SageMaker で使用する方法を、ビルド済みのコンテナを利用して紹介します。Scikit-learn は人気の Python 機械学習フレームワークです。分類、回帰、クラスタリング、次元削減、データ/フィーチャの前処理のための多くの異なるアルゴリズムが含まれています。\n",
    "\n",
    "[sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk)モジュールを使えば、既存のscikit-learnコードを簡単に利用することができます。ここでは、Irisデータセットを用いてScikit-learnのモデルを学習し、予測値を生成することを試します。Scikit-learn コンテナの詳細については、[sagemaker-scikit-learn-containers](https://github.com/aws/sagemaker-scikit-learn-container) リポジトリや [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) リポジトリを参照してください。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 事前準備：ライブラリのインストール / セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = \"DEMO-scikit-iris\"\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Amazon SageMaker Training Job - Amazon SageMaker上でモデルを学習する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1 学習用データを Amazon S3 にアップロード \n",
    "Amazon SageMaker でモデルの学習を行うには、まずAmazon S3と呼ばれるAWSのストレージのサービスに対して学習に使用したいデータをアップロードする必要があります。ここでは、機械学習用のデータセットとして有名なIrisデータセットをサンプルデータとして使用します。\n",
    "\n",
    "あらかじめ Amazon SageMaker 側が用意している Amazon S3バケット内のサンプルデータをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "s3_client.download_file(\n",
    "    f\"sagemaker-example-files-prod-{region}\", \"datasets/tabular/iris/iris.data\", \"./data/iris.csv\"\n",
    ")\n",
    "\n",
    "df_iris = pd.read_csv(\"./data/iris.csv\", header=None)\n",
    "df_iris[4] = df_iris[4].map({\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2})\n",
    "iris = df_iris[[4, 0, 1, 2, 3]].to_numpy()\n",
    "np.savetxt(\"./data/iris.csv\", iris, delimiter=\",\", fmt=\"%1.1f, %1.3f, %1.3f, %1.3f, %1.3f\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ローカルにデータを取得したら、SageMaker Python SDK が提供するツールを使用して、データをお客様の AWSアカウント内にあるAmazon S3 バケットにアップロードします。\n",
    "\n",
    "Amazon SageMakerの環境を立ち上げる際に、実は「Amazon SageMaker 用の Amazon S3 バケット」が作成されます。今回はその S3 バケットに対してデータをアップロードしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = \"data\"\n",
    "\n",
    "train_input = sagemaker_session.upload_data(\n",
    "    WORK_DIRECTORY, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2. トレーニング用の Scikit-learn スクリプトを作成する（書き換える） <a class=\"anchor\" id=\"create_sklearn_script\"></a>\n",
    "\n",
    "お客様の中には、ローカルPCでモデル開発を行う際 Jupyter Notebook上でモデルの前処理〜学習〜推論を行われる方もいらっしゃると思います。\n",
    "Amazon SageMaker を用いた場合でも、引き続きJupyter Notebook上で任意の処理を実行できます。ただ、トレーニングを学習用インスタンスで実行する場合は、学習用スクリプト（Pythonファイル）を作成していただく必要があります。\n",
    "\n",
    "### 書き換えが必要な理由\n",
    "Amazon SageMaker では、オブジェクトストレージ Amazon S3 をデータ保管に利用します。例えば、S3 上の学習データを指定すると、自動的に Amazon SageMaker の学習用インスタンスにデータがダウンロードされ、トレーニングスクリプトが実行されます。トレーニングスクリプトを実行した後に、指定したディレクトリにモデルを保存すると、自動的にモデルがS3にアップロードされます。\n",
    "\n",
    "トレーニングスクリプトを SageMaker に持ち込む場合は、以下の点を修正する必要があります。\n",
    "\n",
    "* 学習用インスタンスにダウンロードされた学習データのロード\n",
    "* 学習が完了したときのモデルの保存\n",
    "* これらの修正は、トレーニングスクリプトを任意の環境に持ち込む際の修正と変わらないでしょう。例えば、自身のPCに持ち込む場合も、/home/user/data のようなディレクトリからデータを読み込んで、/home/user/model にモデルを保存したいと考えるかもしれません。同様のことを SageMaker で行う必要があります。\n",
    "\n",
    "### 書き換え方法\n",
    "\n",
    "（詳細には[こちらのサンプルノートブック](https://github.com/aws-samples/aws-ml-jp/blob/main/sagemaker/workshop/lab_bring-your-own-model/tensorflow/tensorflow.ipynb)などを参照ください）\n",
    "\n",
    "SageMaker は `SKLearn` Estimatorを用いて scikit-learn スクリプトを実行することができます。SageMaker 上で実行すると、以下のような学習環境のプロパティにアクセスするための便利な環境変数が利用できます：\n",
    "\n",
    "* `SM_MODEL_DIR`：: モデルの成果物を書き込むディレクトリへのパスを表す文字列。このフォルダに保存された成果物はトレーニングジョブ終了後にS3にアップロードされ、モデルのホスティングに使用される。\n",
    "* `SM_OUTPUT_DIR`： 出力結果を書き込むファイルシステムのパスを表す文字列です。出力結果にはモデルのチェックポイントファイルや、グラフ、その他の保存ファイルが含まれます。これらの成果物は圧縮され、モデルの成果物と同じS3プレフィックスでS3にアップロードされます。\n",
    "\n",
    "また、 `SKLearn` Estimator の `fit()` メソッドを呼び出す際に 'train' と 'test' の2つの入力チャンネルを使用したとすると、以下の環境変数が設定されます。\n",
    "\n",
    "* `SM_CHANNEL_TRAIN`: 'train' channel のデータを含むディレクトリへのパスを表す文字列。\n",
    "* `SM_CHANNEL_TEST`: 'test' channel のデータを含むディレクトリへのパスを表す文字列。\n",
    "\n",
    "典型的なトレーニングスクリプトは、入力チャンネルからデータをロードし、ハイパーパラメータでトレーニングを設定し、モデルをトレーニングし、後でホストできるようにモデルを `model_dir` に保存します。ハイパーパラメータは引数としてスクリプトに渡され、 `argparse.ArgumentParser` インスタンスで取得することができる。例えば、このノートブックで実行するスクリプトは以下のようになります：\n",
    "\n",
    "```python\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters are described here. In this simple example we are just including one hyperparameter.\n",
    "    parser.add_argument('--max_leaf_nodes', type=int, default=-1)\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    input_files = [ os.path.join(args.train, file) for file in os.listdir(args.train) ]\n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(args.train, \"train\"))\n",
    "    raw_data = [ pd.read_csv(file, header=None, engine=\"python\") for file in input_files ]\n",
    "    train_data = pd.concat(raw_data)\n",
    "\n",
    "    # labels are in the first column\n",
    "    train_y = train_data.iloc[:, 0]\n",
    "    train_X = train_data.iloc[:, 1:]\n",
    "\n",
    "    # Here we support a single hyperparameter, 'max_leaf_nodes'. Note that you can add as many\n",
    "    # as your training my require in the ArgumentParser above.\n",
    "    max_leaf_nodes = args.max_leaf_nodes\n",
    "\n",
    "    # Now use scikit-learn's decision tree classifier to train the model.\n",
    "    clf = tree.DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes)\n",
    "    clf = clf.fit(train_X, train_y)\n",
    "\n",
    "    # Print the coefficients of the trained classifier, and save the coefficients\n",
    "    joblib.dump(clf, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "    \n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "※ 補足\n",
    "\n",
    "Scikit-learn コンテナはお客様が作成したトレーニングスクリプトをインポートするため、コンテナがトレーニングコードを実行する際に誤って実行しないように、常にトレーニングコードをメインガード `(if __name__=='__main__':)` に記述する必要があります。モデルの学習時に使用できる環境変数の詳細については、https://github.com/aws/sagemaker-containers をご覧ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.3. SageMaker Estimator の作成 \n",
    "作成した学習スクリプトを使って実際にモデルを学習していきます。Amazon SageMakerでは、学習の際に`Estimator` と呼ばれる、モデルの学習や評価、推論などで決まった処理を抽象化したインターフェースを使用します。\n",
    "\n",
    "今回使用するScikit-learnや、よく機械学習で用いられるフレームワークであるPyTorchやTensorFlowなどに関しては、そのフレームワーク専用のEstimatorを用意しており、そちらを使うことで1から定義するよりもセットアップが簡単です。\n",
    "\n",
    "SageMaker上でScikit-learn学習スクリプトを実行するために、いくつかのコンストラクタ引数を受け付けるsagemaker.sklearn.estimator.sklearn estimatorを作成します。\n",
    "\n",
    "* entry_point： SageMaker が学習と予測のために実行する Python スクリプトへのパス。\n",
    "* role： IAM ロールの ARN。\n",
    "* instance_type (オプション)： 学習用の SageMaker インスタンスタイプ\n",
    "* sagemaker_session（オプション）： SageMaker での学習に使用するセッション。\n",
    "* hyperparameters (オプション)： ハイパーパラメータとして train 関数に渡される辞書。\n",
    "\n",
    "SKLearn Estimatorの詳細はこちらをご覧ください。 https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# Scikit-learn の バージョンを指定\n",
    "FRAMEWORK_VERSION = \"1.2-1\"\n",
    "\n",
    "# 学習に使用したいスクリプトファイル名を指定\n",
    "script_path = \"scikit_learn_iris.py\"\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path, \n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\"max_leaf_nodes\": 30},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.4. Iris データで SKLearn Estimator をトレーニング（Amazon SageMaker Training Job）\n",
    "学習は簡単で、Estimatorに対してfit()を呼び出すだけです！これにより、SageMakerのトレーニングジョブが開始され、データをダウンロードし、（提供されたスクリプトファイル内の）scikit-learnコードを起動し、スクリプトが作成したモデルの成果物を保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sklearn.fit({\"train\": train_input})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （補足）Amazon SageMaker Training Jobでトレーニングする時のメリット\n",
    "「Jupyter Notebook 上 で学習する場合と何が違うの？」と思ったお客様もいらっしゃるかもしれません。Amazon SageMaker Training Jobを用いることのメリットをいくつか紹介しておきます。\n",
    "* **学習専用のインスタンスを立ち上げられる**：「普段は不要だけれど、学習の時だけGPUを使いたい」「学習の時に大量のサーバーを使ってささっと学習を終わらせたい」というような柔軟な使い方が可能になります。\n",
    "* **学習の内容が自動で記録される**：Notebook上だけでモデルの試行錯誤を行なっている場合、「いつどんなパラメータでどんなデータを用いて学習したモデルがどこに保管されているか...」というのが曖昧になりがちです（少なくとも記録が属人化します）。Amazon SageMaker Training Jobとして実行することで、どんなデータ・どんなハイパーパラメータで学習したかなどの学習に関する情報が自動で記録され、後から見返すことができます。\n",
    "* **SageMakerのその他幅広い機能を使うことができる**：例えばMLOpsの機能など、SageMakerに備わっている様々な便利機能を用いて機械学習の開発の効率を高めることができます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. 推論の実行 - 学習されたモデルを使って推論を実行（ Amazon SageMaker で学習したモデルを用いて Amazon SageMaker で推論するパターン）\n",
    "\n",
    "### 2.1. モデルのデプロイ \n",
    "モデルを SageMaker ホスティングにデプロイするには、fit()を実行したEstimator（すなわち学習が終了したEstimator）に対して deploy() を実行するだけです。これにより、リアルタイム推論エンドポイントが立ち上がります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2. データをピックアップして実際に推論してみる\n",
    "それでは実際に推論をしてみましょう。ここでは、トレーニングに使用したデータを抽出し、それに対して予測を行います。\n",
    "\n",
    "（本来であれば、学習に使用していないテスト用のデータを使うべきですが、今回は「デプロイされたエンドポイントを使って推論がちゃんと実行できる」ことを確かめるためにこのように対応しています。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "shape = pd.read_csv(\"data/iris.csv\", header=None)\n",
    "\n",
    "a = [50 * i for i in range(3)]\n",
    "b = [40 + i for i in range(10)]\n",
    "indices = [i + j for i, j in itertools.product(a, b)]\n",
    "\n",
    "test_data = shape.iloc[indices[:-1]]\n",
    "test_X = test_data.iloc[:, 1:]\n",
    "test_y = test_data.iloc[:, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "予測を行うには、deploy()から返されたpredictor上でpredict()を呼び出し、予測を行うデータを渡します。エンドポイントからの出力は、分類予測の数値表現を返します。元のデータセットでは、これらは3つの花のカテゴリ名ですが、この例ではラベルは数値です。解析した元のラベルと比較をしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(predictor.predict(test_X.values))\n",
    "print(test_y.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "無事結果が返ってきました。（学習に使ったデータをそのまま推論に使用しているので当たり前ですが、）実際のラベルと予測されたラベルが一致していることが確認できました。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.3. エンドポイントのクリーンアップ\n",
    "predict()メソッドを実行すると、エンドポイント、すなわち推論用のインスタンスが立ち上がっています。エンドポイントを使い終わったら、それを削除してリソースを解放し、追加コストが発生しないようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 学習されたモデルを使って推論を実行（ Amazon SageMaker の外で学習されたモデルを用いて Amazon SageMaker で推論するパターン）\n",
    "\n",
    "お客様によってはすでにどこかで学習されたモデルをAmazon SageMaker上で推論に用いたい、という場合があると思います。ここからはその手順について見てみましょう。（ちなみにこのようなパターンを「BYOM；Bring Your Own Model」と呼びます。）\n",
    "\n",
    "### 3.1. 準備：モデルをSageMaker Studio Notebookインスタンスにダウンロード\n",
    "**今回は「あらかじめローカルで学習されたモデル」を模擬するために、先ほどAmazon SageMaker Trainingで学習したモデルのファイルを用いることにします。**\n",
    "\n",
    "まずは先ほどの学習結果のモデルがどこに保存されているのかを確認します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn.model_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、こちらのモデルをダウンロードしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./model/\", exist_ok=True)\n",
    "sagemaker.s3.S3Downloader.download(\n",
    "    s3_uri=sklearn.model_data,\n",
    "    local_path='./model/'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ご覧の通り\"model.tar.gz\"というファイル名が確認できたかと思います。Amazon SageMaker Trainingでは、モデルの出力結果は「tar.gz ファイル」の形で圧縮されて出力されています。こちらを解凍することで実際のモデルファイルを確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tar.gz の解凍\n",
    "import tarfile\n",
    "with tarfile.open('./model/model.tar.gz') as tar:\n",
    "    tar.extractall('./model/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. 準備：ダウンロードしたモデルの読み込みを試してみる\n",
    "SageMaker Training で学習したモデルファイル（今回はjoblibファイル）は当然ながら SageMaker Studio Notebook上でも Loadすればそのまま使用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = './model/model.joblib'\n",
    "sk_local_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sk_local_model.predict(test_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. tar.gz に圧縮したモデルを S3 にアップロードする\n",
    "ではここから、手元にあるモデルファイル（`./model/model.joblib`）を使ってAmazon SageMakerの推論エンドポイントを立てる方法を学んでいきます。\n",
    "まずは、手元にあるモデルファイルを Amazon S3にアップロードしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 圧縮\n",
    "%cd {model_dir}\n",
    "!rm model.tar.gz\n",
    "!tar zcvf model.tar.gz ./*\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.session.Session()\n",
    "bucket = sess.default_bucket()\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y%m%d%H%M%S')\n",
    "model_s3_path = f's3://{bucket}/iris-model-{timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path = tar_name,\n",
    "    desired_s3_uri = model_s3_path\n",
    ")\n",
    "print(model_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. S3 にアップロードしたモデルを SageMaker 管理のモデルとして登録する\n",
    "Amazon SageMaker で推論エンドポイントを立てるためには、作成したモデルを Amazon SageMaker側に登録させる必要があります。Amazon SageMaker Trainingで学習したモデルは、学習完了時に自動的に登録がなされますが、今回のBYOMパターンの場合は明示的に登録する設定が必要です。\n",
    "\n",
    "Scikit-Learn で作成したモデルは `SKLearnModel` で読み込みます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. モデル登録 - 推論用スクリプトを作成する\n",
    "BYOMの場合は、学習の時に学習用スクリプトを作成したのと同様に、推論用のスクリプトを作成する必要があります。このスクリプトの書き方にはお作法があり、以下の二つの関数を定義する必要があります。\n",
    "* `model_fn(model_dir)`：`model_dir`の中には、先ほどAmazon S3にアップロードしたモデルが入っています。こちらをLoadする処理を記載します。\n",
    "* `predict_fn(input_data, model)`：ロードしたモデルに対してデータを入力する処理を記載します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./inference.py\n",
    "import os, joblib\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, 'model.joblib'))\n",
    "    return model\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearnModel\n",
    "sklearn_model = SKLearnModel(\n",
    "    entry_point='./inference.py',\n",
    "    model_data=model_s3_uri,\n",
    "    role= role,\n",
    "    framework_version = '1.2-1',\n",
    "    py_version='py3',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2. 登録したモデルのデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name =  'iris-model-Endpoint'\n",
    "sklearn_predictor = sklearn_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デプロイに成功したら、先ほどと同じテストデータを入力してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_predictor.predict(test_X.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "無事同じ出力を得ることができました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. デプロイしたモデルを使ってSageMakerの外から推論する\n",
    "このようにしてデプロイしたモデルは、Amazon SageMaker のノートブック以外の環境から利用することができるようになります。\n",
    "AWSの様々なサービスのAPIを利用するためのライブラリであるAWS SDK（Pythonの場合は「Boto3」という名前のライブラリ）を使用することで可能になります。\n",
    "\n",
    "適切な権限があればどこからでも実行できますが、ここでは簡単のためにSageMaker Studio Notebook上で実行してみます。試してみたい方は、AWS Lambdaなどの別サービスに下記コードをコピペしてみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Boto3のインポート\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=str(test_X.values.tolist()),\n",
    "    ContentType='application/json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = np.array(json.load(response['Body']))\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.6. エンドポイントのクリーンアップ\n",
    "終わったらエンドポイントを消去します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. (Optional) 推論方式の変更 - サーバーレス推論を実行してみる\n",
    "Amazon SageMaker では現在4つの推論方式をサポートしています。これまでみてきたエンドポイントのパターンは「リアルタイム推論」でした。常にエンドポイントが立ち上がっているため最もリアルタイムに推論の結果を返すことができます。\n",
    "\n",
    "その他にも、推論を行いたいパターンに応じて推論方式を選択できます。一度SageMaker側にモデルを登録すれば、簡単に推論の方式を変えられます。今回はサーバーレス推論のパターンを試してみましょう。\n",
    "\n",
    "その他の推論方式を含む詳細については、こちらのドキュメントをご覧ください。https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-serverless-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. サーバーレス推論に関する設定値を決定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "\n",
    "# デフォルトの設定値を参照\n",
    "serverless_config = ServerlessInferenceConfig()\n",
    "\n",
    "# 設定したい場合はこちら\n",
    "# serverless_config = ServerlessInferenceConfig(\n",
    "#   memory_size_in_mb=4096,\n",
    "#   max_concurrency=10,\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. サーバーレス推論エンドポイントのデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serverless_predictor = sklearn_model.deploy(serverless_inference_config=serverless_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. 推論の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3, json\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=serverless_predictor.endpoint,\n",
    "    Body=str(test_X.values.tolist()),\n",
    "    ContentType='application/json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 5. (Optional) バッチ変換 <a class=\"anchor\" id=\"batch_transform\"></a>\n",
    "ここまで、リクエストが来たものに対して同期的に推論を実行し予測結果を返すエンドポイントを見てきました。ただ、ユースケースによっては、推論の頻度は低いものの大量のデータを一気に推論にかけてしまいたい、というケースもあるかと思います。そんな時に最適なのが、バッチ変換（Batch Transform）という推論方式です。通常時インスタンスは稼働せず、バッチ変換のリクエストが来た時に推論用インスタンスを立て、終了したら自動でインスタンスは消去されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define an SKLearn Transformer from the trained SKLearn Estimator\n",
    "transformer = sklearn.transformer(instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.1. 入力データの準備\n",
    "トレーニングデータから100行のランダムサンプルを10個抽出し、ラベル（Y）から特徴（X）を分割し、入力データをS3の所定の場所にアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Randomly sample the iris dataset 10 times, then split X and Y\n",
    "mkdir -p batch_data/XY batch_data/X batch_data/Y\n",
    "for i in {0..9}; do\n",
    "    cat data/iris.csv | shuf -n 100 > batch_data/XY/iris_sample_${i}.csv\n",
    "    cat batch_data/XY/iris_sample_${i}.csv | cut -d',' -f2- > batch_data/X/iris_sample_X_${i}.csv\n",
    "    cat batch_data/XY/iris_sample_${i}.csv | cut -d',' -f1 > batch_data/Y/iris_sample_Y_${i}.csv\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Upload input data from local file system to S3\n",
    "batch_input_s3 = sagemaker_session.upload_data(\"batch_data/X\", key_prefix=prefix + \"/batch_input\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.2.変換ジョブの実行 <a class=\"anchor\" id=\"run_transform_job\"></a>\n",
    "Amazon S3にあるデータをまとめて推論します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start a transform job and wait for it to finish\n",
    "transformer.transform(batch_input_s3, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.3.出力データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download the output data from S3 to local file system\n",
    "batch_output = transformer.output_path\n",
    "!mkdir -p batch_data/output\n",
    "!aws s3 cp --recursive $batch_output/ batch_data/output/\n",
    "# Head to see what the batch output looks like\n",
    "!head batch_data/output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# For each sample file, compare the predicted labels from batch output to the true labels\n",
    "for i in {1..9}; do\n",
    "    diff -s batch_data/Y/iris_sample_Y_${i}.csv \\\n",
    "        <(cat batch_data/output/iris_sample_X_${i}.csv.out | sed 's/[[\"]//g' | sed 's/, \\|]/\\n/g') \\\n",
    "        | sed \"s/\\/dev\\/fd\\/63/batch_data\\/output\\/iris_sample_X_${i}.csv.out/\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
